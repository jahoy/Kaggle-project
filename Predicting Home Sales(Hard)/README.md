[Dataset](https://www.kaggle.com/c/home-data-for-ml-course/data)

# Prediciting Home Sales(hard_version)
`Ridge`, `Lasso`, `ElasticNet`, `xgboost`, `lightgbm`  모델들을 활용하여 `Stacking`(앙상블) 방법을 통해 모델 구축 
- Rank in Top 1% (상위 1% 성적)








데이터들의 특징
1. 결측치 언급  - 숫자형끼리, 카데고리형끼리 따로따로 처리해야함
2. 데이터형식을 보니, 오브젝트가많다.
3. 칼럼들마다 범위가 큰것도 있고, 어떤 칼럼은 범위가 작다.
4. 이 데이터셋을 보자마자, 사용할 수 있는 모델이 떠올라야한다.
= 데이터셋 - 거리가 중요한 칼럼들이 많다., 카데고리형 칼럼들이 많다., 데이터수가 적다 - 1400개(overfit, underfit(bias 현상)일어날수 있음)
=> 트리말고도 선형모델을 쓰는게 나을듯

여러 모델을 사용해서 예측을 하는 앙상블 기법이 사실 과적합 방지 기법이기도 하다!
1. 여러가지 관점으로 학습: generalize
2. variance 줄여준다.



모델 6개를 만들어서 스태킹 활용, 앙상블 기법 활용
1. 이 데이터셋에 들어있는 칼럼들의 내용을 보니, 정말 숫자들에 의미가 있는 칼럼들이 많으므로 선형모델이나 거리기반의 학습을 하는 모델들을 이용할 수 있을것 같다.
2. 카테고리형 변수도 꽤 있다? 그러면 트리모델도 이용해야겠다.
3. 앙상블 통해서 1번 2번 을 합쳐줌
4. 데이터의 수가 적다! 데이터가 적으면 상대적으로 트리모델과 뉴럴네트워크 모델들의 성능이 떨어진다. 데이터의 갯수가 적을때, 트레인셋과 테스트셋의 분포가 다르면 트레인셋이 테스트셋을 충분히 반영하지 못하기 때문에!!
